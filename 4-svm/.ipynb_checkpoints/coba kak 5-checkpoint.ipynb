{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77b7c54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Vectorizer\n",
      "\n",
      "      cari  driver  kah  kak  kota  laper  promonya  selamat  shopeefood  \\\n",
      "Doc1     0       0    0    0     1      0         0        1           1   \n",
      "Doc2     1       1    1    0     0      1         0        0           1   \n",
      "Doc3     0       0    0    1     0      0         1        0           1   \n",
      "\n",
      "      sulit  \n",
      "Doc1      0  \n",
      "Doc2      1  \n",
      "Doc3      0  \n",
      "\n",
      "TD-IDF Vectorizer\n",
      "\n",
      "         cari    cepat   driver     enak  habis  kota    makan  promonya  \\\n",
      "Doc1  0.00000  0.57735  0.00000  0.57735    0.0   0.0  0.57735       0.0   \n",
      "Doc2  0.57735  0.00000  0.57735  0.00000    0.0   0.0  0.00000       0.0   \n",
      "Doc3  0.00000  0.00000  0.00000  0.00000    0.5   0.5  0.00000       0.5   \n",
      "\n",
      "      shopeefood  sulit  \n",
      "Doc1     0.00000    0.0  \n",
      "Doc2     0.57735    0.0  \n",
      "Doc3     0.00000    0.5  \n"
     ]
    }
   ],
   "source": [
    "# TfidfVectorizer \n",
    "# CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "import pandas as pd\n",
    "# set of documents\n",
    "train = ['selamat kota shopeefood','sulit cari driver shopeefood kah laper', 'shopeefood promonya kak']\n",
    "test = ['cepat makan enak', 'cari driver shopeefood', 'promonya kota sulit habis']\n",
    "\n",
    "# instantiate the vectorizer object\n",
    "countvectorizer = CountVectorizer(analyzer= 'word')\n",
    "tfidfvectorizer = TfidfVectorizer(analyzer='word')\n",
    "# convert th documents into a matrix\n",
    "count_wm = countvectorizer.fit_transform(train)\n",
    "tfidf_wm = tfidfvectorizer.fit_transform(test)\n",
    "#retrieve the terms found in the corpora\n",
    "# if we take same parameters on both Classes(CountVectorizer and TfidfVectorizer) , it will give same output of get_feature_names() methods)\n",
    "#count_tokens = tfidfvectorizer.get_feature_names() # no difference\n",
    "count_tokens = countvectorizer.get_feature_names_out()\n",
    "tfidf_tokens = tfidfvectorizer.get_feature_names_out()\n",
    "df_countvect = pd.DataFrame(data = count_wm.toarray(),index = ['Doc1','Doc2', 'Doc3'],columns = count_tokens)\n",
    "df_tfidfvect = pd.DataFrame(data = tfidf_wm.toarray(),index = ['Doc1','Doc2', 'Doc3'],columns = tfidf_tokens)\n",
    "print(\"Count Vectorizer\\n\")\n",
    "print(df_countvect)\n",
    "print(\"\\nTD-IDF Vectorizer\\n\")\n",
    "print(df_tfidfvect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1412a432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparse Matrix form of test data : \n",
      "\n",
      "[[0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "terms = countvectorizer.fit_transform(train)\n",
    "term_vectors  = countvectorizer.transform(test)\n",
    "print(\"Sparse Matrix form of test data : \\n\")\n",
    "print(term_vectors.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e957249",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This SVC instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12108/177103533.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mreview\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"iseng pesan makan shopeefood enak\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mreview_vector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtfidfvectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mreview\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# vectorizing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreview_vector\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    776\u001b[0m             \u001b[0mClass\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    777\u001b[0m         \"\"\"\n\u001b[1;32m--> 778\u001b[1;33m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    779\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbreak_ties\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function_shape\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"ovo\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    780\u001b[0m             raise ValueError(\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1208\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfitted\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1209\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"name\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This SVC instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "review = \"iseng pesan makan shopeefood enak\"\n",
    "review_vector = tfidfvectorizer.transform([review]) # vectorizing\n",
    "print(clf.predict(review_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f2f3be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf = svm.SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c90649c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
